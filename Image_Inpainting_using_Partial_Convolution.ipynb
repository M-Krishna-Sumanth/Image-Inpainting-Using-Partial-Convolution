{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Image Inpainting using Partial Convolution.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8ewTdvytygk6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import PIL\n",
        "import torch\n",
        "import torchvision\n",
        "import torchsummary\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Setting the device"
      ],
      "metadata": {
        "id": "IZhab40nVmsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "stqp1FFs9gC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Custom Dataset"
      ],
      "metadata": {
        "id": "iAb6A_NcVrM9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "  def __init__(self, image_dir, mask_dir):\n",
        "    self.image_dir = image_dir\n",
        "    self.mask_dir = mask_dir\n",
        "    self.images = os.listdir(image_dir)\n",
        "      \n",
        "  def __len__(self):\n",
        "    return len(self.images)\n",
        "      \n",
        "  def __getitem__(self, idx):\n",
        "    image_path = os.path.join(self.image_dir, self.images[idx])\n",
        "    mask_path = os.path.join(self.mask_dir, self.images[idx].replace('.jpg','_mask.gif'))\n",
        "    image = PIL.Image.open(image_path)\n",
        "    image = torchvision.transforms.Resize((256, 256))(image)\n",
        "    image = (torchvision.transforms.ToTensor()(image)).unsqueeze(0).to(device)\n",
        "    mask = PIL.Image.open(mask_path)\n",
        "    mask = torchvision.transforms.Resize((256, 256))(mask)\n",
        "    mask = (torchvision.transforms.ToTensor()(mask)).unsqueeze(0).to(device)\n",
        "\n",
        "    return image, mask"
      ],
      "metadata": {
        "id": "nZQF8mtypoJ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Partial Convolution"
      ],
      "metadata": {
        "id": "pwjGf8rQVwHh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PartialConv2d(torch.nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, kernerl_size, stride, padding):\n",
        "    super(PartialConv2d, self).__init__()\n",
        "    self.input_conv = torch.nn.Conv2d(in_channels, out_channels, kernerl_size, stride, padding)\n",
        "    self.mask_conv  = torch.nn.Conv2d(in_channels, out_channels, kernerl_size, stride, padding, bias=False)\n",
        "    torch.nn.init.kaiming_normal_(self.input_conv.weight, a=0, mode=\"fan_in\")\n",
        "    torch.nn.init.constant_(self.mask_conv.weight, 1.0)\n",
        "    for param in self.mask_conv.parameters():\n",
        "      param.requires_grad = False\n",
        "\n",
        "  def forward(self, X, M):\n",
        "    output = self.input_conv(X * M)\n",
        "    output_mask = self.mask_conv(M)\n",
        "    output_bias = self.input_conv.bias.view(1, -1, 1, 1).expand_as(output)\n",
        "    # mask_sum is the sum of the binary mask at every partial convolution location\n",
        "    mask_is_zero = (output_mask == 0)\n",
        "    # temporarily sets zero values to one to ease output calculation\n",
        "    mask_sum = output_mask.masked_fill_(mask_is_zero, 1.0)\n",
        "    \n",
        "    # output at each location as follows:\n",
        "    # output = (W^T dot (X * M) + b - b) /  M_sum + b ; if M_sum > 0\n",
        "    # output = 0 ; if M_sum == 0\n",
        "    output = (output - output_bias) / mask_sum + output_bias\n",
        "    output = output.masked_fill_(mask_is_zero, 0.0)\n",
        "    \n",
        "    # mask is updated at each location\n",
        "    new_mask = torch.ones_like(output)\n",
        "    new_mask = new_mask.masked_fill_(mask_is_zero, 0.0)\n",
        "\n",
        "    return output, new_mask\n",
        "\n",
        "class Conv(torch.nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, stride, padding, bn, act):\n",
        "    super().__init__()\n",
        "    self.layers = torch.nn.ModuleList()\n",
        "    self.layers.append(PartialConv2d(in_channels, out_channels, kernel_size, stride, padding))\n",
        "    if bn:\n",
        "      self.layers.append(torch.nn.BatchNorm2d(out_channels))\n",
        "    if act=='relu':\n",
        "      self.layers.append(torch.nn.ReLU())\n",
        "    elif act=='leaky_relu':\n",
        "      self.layers.append(torch.nn.LeakyReLU(0.2))\n",
        "\n",
        "  def forward(self, X, M):\n",
        "    for layer in self.layers:\n",
        "      if isinstance(layer, PartialConv2d):\n",
        "        X, M = layer(X, M)\n",
        "      else:\n",
        "        X = layer(X)\n",
        "    return X, M"
      ],
      "metadata": {
        "id": "0sdtoADK8ZXu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# UNet"
      ],
      "metadata": {
        "id": "qmp_iDQZV1Pv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class UNet(torch.nn.Module):\n",
        "  def __init__(self, in_channels=3, encoder_kernels = [7,5,5,3,3,3,3,3], encoder_channels = [64,128,256,512,512,512,512,512], \\\n",
        "                                    decoder_kernels = [3,3,3,3,3,3,3,3], decoder_channels = [512,512,512,512,256,128,64,3] ):\n",
        "    super(UNet, self).__init__()\n",
        "    self.in_channels = 3\n",
        "    self.downs = torch.nn.ModuleList()\n",
        "    self.ups = torch.nn.ModuleList()\n",
        "    for num, out_channels, kernel_size in zip(range(len(encoder_kernels)), encoder_channels, encoder_kernels):\n",
        "      if num!=0:bn=True\n",
        "      else:bn=False\n",
        "      self.downs.append(Conv(in_channels, out_channels, kernel_size, 2, kernel_size//2, bn, 'relu'))\n",
        "      in_channels = out_channels\n",
        "    encoder_channels = encoder_channels[:-1][::-1]\n",
        "    encoder_channels.append(3)\n",
        "    for num, out_channels, kernel_size in zip(range(len(decoder_kernels)), decoder_channels, decoder_kernels):\n",
        "      if num==len(decoder_kernels)-1:bn=False\n",
        "      else:bn=True\n",
        "      in_channels=in_channels+encoder_channels[num]\n",
        "      self.ups.append(Conv(in_channels, out_channels, kernel_size, 1, kernel_size//2, bn, 'leaky_relu'))\n",
        "      in_channels=out_channels\n",
        "\n",
        "  def forward(self, X, M):\n",
        "    self.X = X\n",
        "    self.M = M\n",
        "    skip_conctns = []\n",
        "    for idx, down in enumerate(self.downs):\n",
        "      X, M = down(X,M)\n",
        "      skip_conctns.append([X,M])\n",
        "    skip_conctns = skip_conctns[:-1][::-1]\n",
        "    skip_conctns.append([self.X,self.M])\n",
        "    for idx, up in enumerate(self.ups):\n",
        "      X = F.interpolate(X,scale_factor=2)\n",
        "      M = F.interpolate(M,scale_factor=2)\n",
        "      skip_conctn = skip_conctns[idx]\n",
        "      X = torch.cat((skip_conctn[0],X), dim=1)\n",
        "      M = torch.cat((skip_conctn[1],M), dim=1)\n",
        "      X, M = up(X,M)\n",
        "\n",
        "    return X, M"
      ],
      "metadata": {
        "id": "8-KlwlwYWC5k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Loss"
      ],
      "metadata": {
        "id": "9xVQduJPWDHX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Loss:\n",
        "  def __init__(self, I_out, I_gt, I_in, M, lambdas=[1, 6, 0.05, 120, 0.1], layer_nums=[4, 9, 16]):\n",
        "    self.I_out = I_out\n",
        "    self.I_gt = I_gt\n",
        "    self.I_in = I_in\n",
        "    self.I_comp = self.I_in*self.M + self.I_out*(1-self.M)\n",
        "    self.M  = M\n",
        "    self.model = torchvision.models.vgg16(pretrained=True).eval().features[:17].to(device)\n",
        "    self.lambdas = lambdas\n",
        "    self.layer_nums = layer_nums\n",
        "    self.l1loss = torch.nn.L1Loss()\n",
        "\n",
        "  def generate_features(self, x):\n",
        "    features = []\n",
        "    for num, layer in enumerate(self.model):\n",
        "      x = layer(x)\n",
        "      if num in self.layer_nums:\n",
        "        features.append(x)\n",
        "    return features\n",
        "\n",
        "  def gram_matrix(self, feature_matrix):\n",
        "    B, C, H, W = feature_matrix.size()\n",
        "    feature_matrix = feature_matrix.view(B, C, H * W)\n",
        "    feature_matrix_t = feature_matrix.transpose(1, 2)\n",
        "  \n",
        "    # batch matrix multiplication * normalization factor K_n\n",
        "    # (B, C, H * W) x (B, H * W, C) ==> (B, C, C)\n",
        "    # size = (B, C, C)\n",
        "    return torch.bmm(feature_matrix, feature_matrix_t) / (C*H*W)\n",
        "\n",
        "  def total_loss(self):\n",
        "    I_comp_features = self.generate_featutes(self.I_comp)\n",
        "    I_out_features  = self.generate_featutes(self.I_out)\n",
        "    I_gt_features   = self.generate_featutes(self.I_gt)\n",
        "\n",
        "    I_comp_gram = self.gram_matrix(self.I_comp)\n",
        "    I_out_gram  = self.gram_matrix(self.I_out)\n",
        "    I_gt_gram   = self.gram_matrix(self.I_gt)\n",
        "\n",
        "    L_valid      = self.l1loss(self.M*self.I_out, self.M*self.I_gt)\n",
        "    L_hole       = self.l1loss((1-self.M)*self.I_out, (1-self.M)*self.I_gt)\n",
        "    L_perceptual = self.l1loss(I_out_features, I_gt_features)+self.l1loss(I_comp_features, I_gt_features)\n",
        "    L_style      = self.l1loss(I_out_gram, I_gt_gram)+self.l1loss(I_comp_gram, I_gt_gram)\n",
        "    L_tv         = self.l1loss(self.I_comp[:, :, :, :-1], self.I_comp[:, :, :, 1:]) + self.l1loss(self.I_comp[:, :, :-1, :], self.I_comp[:, :, 1:, :])\n",
        "\n",
        "    return self.lambdas[0]*L_valid + self.lambdas[1]*L_hole + self.lambdas[2]*L_perceptual + self.lambdas[3]*L_style + self.lambdas[4]*L_tv"
      ],
      "metadata": {
        "id": "yi-wD04x7AMg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_chkpt(model, optim, filename='drive/MyDrive/UNet.pth.tar'):\n",
        "  chkpt = {'model':model.state_dict(),'optim':optim.state_dict()}\n",
        "  torch.save(chkpt, filename)\n",
        "\n",
        "def load_chkpt(model, optim, filename='drive/MyDrive/UNet.pth.tar'):\n",
        "  chkpt = torch.load(filename)\n",
        "  model.load_state_dict(chkpt['model'])\n",
        "  optim.load_state_dict(chkpt['optim'])"
      ],
      "metadata": {
        "id": "v5f_EQcnc9L3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = UNet()"
      ],
      "metadata": {
        "id": "7sKTMPXkoEKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epoch_losses = [] \n",
        "def train(x_train, y_train, model, optim, loss_fn, epochs):\n",
        "  train_set = Dataset(x_train, y_train)\n",
        "  train_loader = torch.utils.data.DataLoader(train_set, 16, True)\n",
        "  for epoch in range(epochs):\n",
        "    batch_losses = []\n",
        "    if epoch%1==0 and epoch!=0:\n",
        "      save_chkpt(model, optim)\n",
        "    loop = tqdm(train_loader,  position=0, leave=True)\n",
        "    for x, y in loop:\n",
        "      x, y = x.to(device), y.to(device)\n",
        "      y_hat = model(x)\n",
        "      loss = loss_fn(y_hat, y)\n",
        "      batch_losses.append(loss.item())\n",
        "      optim.zero_grad()\n",
        "      loss.backward()\n",
        "      optim.step()\n",
        "      loop.set_postfix(loss=loss)\n",
        "\n",
        "    epoch_losses.append(sum(batch_losses)/len(batch_losses))\n",
        "  return"
      ],
      "metadata": {
        "id": "p8fZ8B7YYJ30"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torchsummary.summary(model,[(3,256,256),(3,256,256)])"
      ],
      "metadata": {
        "id": "iCIUsCV28bMa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38981a95-6850-4ae9-9661-0c501a2a7cf2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 128, 128]           9,472\n",
            "            Conv2d-2         [-1, 64, 128, 128]           9,408\n",
            "     PartialConv2d-3  [[-1, 64, 128, 128], [-1, 64, 128, 128]]               0\n",
            "              ReLU-4         [-1, 64, 128, 128]               0\n",
            "              Conv-5  [[-1, 64, 128, 128], [-1, 64, 128, 128]]               0\n",
            "            Conv2d-6          [-1, 128, 64, 64]         204,928\n",
            "            Conv2d-7          [-1, 128, 64, 64]         204,800\n",
            "     PartialConv2d-8  [[-1, 128, 64, 64], [-1, 128, 64, 64]]               0\n",
            "       BatchNorm2d-9          [-1, 128, 64, 64]             256\n",
            "             ReLU-10          [-1, 128, 64, 64]               0\n",
            "             Conv-11  [[-1, 128, 64, 64], [-1, 128, 64, 64]]               0\n",
            "           Conv2d-12          [-1, 256, 32, 32]         819,456\n",
            "           Conv2d-13          [-1, 256, 32, 32]         819,200\n",
            "    PartialConv2d-14  [[-1, 256, 32, 32], [-1, 256, 32, 32]]               0\n",
            "      BatchNorm2d-15          [-1, 256, 32, 32]             512\n",
            "             ReLU-16          [-1, 256, 32, 32]               0\n",
            "             Conv-17  [[-1, 256, 32, 32], [-1, 256, 32, 32]]               0\n",
            "           Conv2d-18          [-1, 512, 16, 16]       1,180,160\n",
            "           Conv2d-19          [-1, 512, 16, 16]       1,179,648\n",
            "    PartialConv2d-20  [[-1, 512, 16, 16], [-1, 512, 16, 16]]               0\n",
            "      BatchNorm2d-21          [-1, 512, 16, 16]           1,024\n",
            "             ReLU-22          [-1, 512, 16, 16]               0\n",
            "             Conv-23  [[-1, 512, 16, 16], [-1, 512, 16, 16]]               0\n",
            "           Conv2d-24            [-1, 512, 8, 8]       2,359,808\n",
            "           Conv2d-25            [-1, 512, 8, 8]       2,359,296\n",
            "    PartialConv2d-26  [[-1, 512, 8, 8], [-1, 512, 8, 8]]               0\n",
            "      BatchNorm2d-27            [-1, 512, 8, 8]           1,024\n",
            "             ReLU-28            [-1, 512, 8, 8]               0\n",
            "             Conv-29  [[-1, 512, 8, 8], [-1, 512, 8, 8]]               0\n",
            "           Conv2d-30            [-1, 512, 4, 4]       2,359,808\n",
            "           Conv2d-31            [-1, 512, 4, 4]       2,359,296\n",
            "    PartialConv2d-32  [[-1, 512, 4, 4], [-1, 512, 4, 4]]               0\n",
            "      BatchNorm2d-33            [-1, 512, 4, 4]           1,024\n",
            "             ReLU-34            [-1, 512, 4, 4]               0\n",
            "             Conv-35  [[-1, 512, 4, 4], [-1, 512, 4, 4]]               0\n",
            "           Conv2d-36            [-1, 512, 2, 2]       2,359,808\n",
            "           Conv2d-37            [-1, 512, 2, 2]       2,359,296\n",
            "    PartialConv2d-38  [[-1, 512, 2, 2], [-1, 512, 2, 2]]               0\n",
            "      BatchNorm2d-39            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-40            [-1, 512, 2, 2]               0\n",
            "             Conv-41  [[-1, 512, 2, 2], [-1, 512, 2, 2]]               0\n",
            "           Conv2d-42            [-1, 512, 1, 1]       2,359,808\n",
            "           Conv2d-43            [-1, 512, 1, 1]       2,359,296\n",
            "    PartialConv2d-44  [[-1, 512, 1, 1], [-1, 512, 1, 1]]               0\n",
            "      BatchNorm2d-45            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-46            [-1, 512, 1, 1]               0\n",
            "             Conv-47  [[-1, 512, 1, 1], [-1, 512, 1, 1]]               0\n",
            "           Conv2d-48            [-1, 512, 2, 2]       4,719,104\n",
            "           Conv2d-49            [-1, 512, 2, 2]       4,718,592\n",
            "    PartialConv2d-50  [[-1, 512, 2, 2], [-1, 512, 2, 2]]               0\n",
            "      BatchNorm2d-51            [-1, 512, 2, 2]           1,024\n",
            "        LeakyReLU-52            [-1, 512, 2, 2]               0\n",
            "             Conv-53  [[-1, 512, 2, 2], [-1, 512, 2, 2]]               0\n",
            "           Conv2d-54            [-1, 512, 4, 4]       4,719,104\n",
            "           Conv2d-55            [-1, 512, 4, 4]       4,718,592\n",
            "    PartialConv2d-56  [[-1, 512, 4, 4], [-1, 512, 4, 4]]               0\n",
            "      BatchNorm2d-57            [-1, 512, 4, 4]           1,024\n",
            "        LeakyReLU-58            [-1, 512, 4, 4]               0\n",
            "             Conv-59  [[-1, 512, 4, 4], [-1, 512, 4, 4]]               0\n",
            "           Conv2d-60            [-1, 512, 8, 8]       4,719,104\n",
            "           Conv2d-61            [-1, 512, 8, 8]       4,718,592\n",
            "    PartialConv2d-62  [[-1, 512, 8, 8], [-1, 512, 8, 8]]               0\n",
            "      BatchNorm2d-63            [-1, 512, 8, 8]           1,024\n",
            "        LeakyReLU-64            [-1, 512, 8, 8]               0\n",
            "             Conv-65  [[-1, 512, 8, 8], [-1, 512, 8, 8]]               0\n",
            "           Conv2d-66          [-1, 512, 16, 16]       4,719,104\n",
            "           Conv2d-67          [-1, 512, 16, 16]       4,718,592\n",
            "    PartialConv2d-68  [[-1, 512, 16, 16], [-1, 512, 16, 16]]               0\n",
            "      BatchNorm2d-69          [-1, 512, 16, 16]           1,024\n",
            "        LeakyReLU-70          [-1, 512, 16, 16]               0\n",
            "             Conv-71  [[-1, 512, 16, 16], [-1, 512, 16, 16]]               0\n",
            "           Conv2d-72          [-1, 256, 32, 32]       1,769,728\n",
            "           Conv2d-73          [-1, 256, 32, 32]       1,769,472\n",
            "    PartialConv2d-74  [[-1, 256, 32, 32], [-1, 256, 32, 32]]               0\n",
            "      BatchNorm2d-75          [-1, 256, 32, 32]             512\n",
            "        LeakyReLU-76          [-1, 256, 32, 32]               0\n",
            "             Conv-77  [[-1, 256, 32, 32], [-1, 256, 32, 32]]               0\n",
            "           Conv2d-78          [-1, 128, 64, 64]         442,496\n",
            "           Conv2d-79          [-1, 128, 64, 64]         442,368\n",
            "    PartialConv2d-80  [[-1, 128, 64, 64], [-1, 128, 64, 64]]               0\n",
            "      BatchNorm2d-81          [-1, 128, 64, 64]             256\n",
            "        LeakyReLU-82          [-1, 128, 64, 64]               0\n",
            "             Conv-83  [[-1, 128, 64, 64], [-1, 128, 64, 64]]               0\n",
            "           Conv2d-84         [-1, 64, 128, 128]         110,656\n",
            "           Conv2d-85         [-1, 64, 128, 128]         110,592\n",
            "    PartialConv2d-86  [[-1, 64, 128, 128], [-1, 64, 128, 128]]               0\n",
            "      BatchNorm2d-87         [-1, 64, 128, 128]             128\n",
            "        LeakyReLU-88         [-1, 64, 128, 128]               0\n",
            "             Conv-89  [[-1, 64, 128, 128], [-1, 64, 128, 128]]               0\n",
            "           Conv2d-90          [-1, 3, 256, 256]           1,812\n",
            "           Conv2d-91          [-1, 3, 256, 256]           1,809\n",
            "    PartialConv2d-92  [[-1, 3, 256, 256], [-1, 3, 256, 256]]               0\n",
            "        LeakyReLU-93          [-1, 3, 256, 256]               0\n",
            "             Conv-94  [[-1, 3, 256, 256], [-1, 3, 256, 256]]               0\n",
            "================================================================\n",
            "Total params: 65,714,085\n",
            "Trainable params: 32,865,236\n",
            "Non-trainable params: 32,848,849\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 147456.00\n",
            "Forward/backward pass size (MB): 45189132.86\n",
            "Params size (MB): 250.68\n",
            "Estimated Total Size (MB): 45336839.54\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    }
  ]
}